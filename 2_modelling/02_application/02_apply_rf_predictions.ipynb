{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3cbf64",
   "metadata": {},
   "source": [
    "# Apply Random Forest Model to City Segments (Global Predictions)\n",
    "\n",
    "This notebook:\n",
    "\n",
    "1. Loads the trained Random Forest model (`rf_best_model.joblib`).\n",
    "2. Iterates over all country folders containing:\n",
    "   - `{country}_segments.shp`\n",
    "   - `{country}_segments_vars_with_ratios.csv`\n",
    "3. Computes `rf_prob` and `rf_label` (using a chosen threshold, e.g. œÑ = 0.40).\n",
    "4. Writes one **GeoPackage per country**:\n",
    "   - `{country}_rf_preds.gpkg` with geometry + RF outputs.\n",
    "\n",
    "---\n",
    "\n",
    "## Data & model locations\n",
    "\n",
    "**Model**\n",
    "\n",
    "- The best RF model is not stored in this repository (file is too large).\n",
    "- There is a text file at:\n",
    "\n",
    "`../01_training/rf_outputs/bestmodel_joblib.txt`\n",
    "\n",
    "which contains the link to a Zenodo archive where  \n",
    "`rf_best_model.joblib` can be downloaded.\n",
    "\n",
    "**Inputs (same as informed in 1_preprocessing step)**\n",
    "\n",
    "1. **City Segments v1 raw data** (shapefiles)  \n",
    "   Must be downloaded from Harvard Dataverse:  \n",
    "   https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/XLRSF0  \n",
    "   Folder structure expected (example):\n",
    "\n",
    "   data/raw/CitySegments/\n",
    "\n",
    "   argentina/\n",
    "\n",
    "   argentina_segments.shp\n",
    "\n",
    "   argentina_segments_vars_with_ratios.csv\n",
    "\n",
    "   brazil/\n",
    "\n",
    "   brazil_segments.shp\n",
    "\n",
    "   brazil_segments_vars_with_ratios.csv\n",
    "   \n",
    "   ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c64afd",
   "metadata": {},
   "source": [
    "\n",
    "2. **Preprocessed CSVs** (`*_segments_vars_with_ratios.csv`)  \n",
    "These are produced in the preprocessing step (1_preprocessing/01_preprocess_city_segments.ipynb) and stored alongside the shapefiles.\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "- GPKGs are written to:\n",
    "\n",
    "`2_modelling/02_application/predictions/`\n",
    "\n",
    "Each file:\n",
    "\n",
    "`{country}_rf_preds.gpkg`\n",
    "\n",
    "Due to size, the full set of prediction GPKGs (for 107 countries)  \n",
    "is not stored in this repository. Instead, a text file in the `predictions/` folder\n",
    "contains a Zenodo link where the complete zip archive is hosted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e764e40",
   "metadata": {},
   "source": [
    "# Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f53b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Configuration (relative paths for the repo)\n",
    "# ------------------------------------------------\n",
    "\n",
    "# RF model path (downloaded from Zenodo, see TXT in rf_outputs folder)\n",
    "MODEL_PATH = Path(\"../01_training/rf_outputs/rf_best_model.joblib\")\n",
    "\n",
    "# Parent folder containing one subfolder per country with:\n",
    "#   {country}_segments.shp\n",
    "#   {country}_segments_vars_with_ratios.csv\n",
    "PARENT_FOLDER = Path(\"../../data/raw/CitySegments\")\n",
    "\n",
    "# Output folder for per-country prediction GPKGs\n",
    "OUTPUT_FOLDER = Path(\"predictions\")\n",
    "OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Classification threshold\n",
    "THRESHOLD = 0.40\n",
    "\n",
    "# Region mapping JSON (created during RF training)\n",
    "REGION_MAP_PATH = Path(\"../01_training/rf_outputs/region_mapping.json\")\n",
    "\n",
    "# EXACT predictor order used in training\n",
    "predictor_cols = [\n",
    "    \"i5_par_area\", \"i1_pop_area\", \"i6_paru_area\", \"i8_paru_par\", \"B_AVG_SEG\",\n",
    "    \"i9_roads_par\", \"PARU_A_SEG\", \"B_AREA_SEG\", \"B_CV_SEG\",\n",
    "    \"REGION_CODE\"\n",
    "]\n",
    "\n",
    "# Parallel workers (use all cores by default)\n",
    "N_JOBS = -1\n",
    "\n",
    "print(\"MODEL_PATH:\", MODEL_PATH.resolve())\n",
    "print(\"PARENT_FOLDER:\", PARENT_FOLDER.resolve())\n",
    "print(\"OUTPUT_FOLDER:\", OUTPUT_FOLDER.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------\n",
    "# Load trained RF model\n",
    "# ------------------\n",
    "if not MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Model file not found at {MODEL_PATH}.\\n\"\n",
    "        \"Download rf_best_model.joblib from the Zenodo link in \"\n",
    "        \"../01_training/rf_outputs/bestmodel_joblib.txt\"\n",
    "    )\n",
    "\n",
    "rf = joblib.load(MODEL_PATH)\n",
    "print(f\"‚úÖ Loaded model: {MODEL_PATH.name}\")\n",
    "\n",
    "try:\n",
    "    print(\"Model expects n_features_in_ =\", rf.n_features_in_)\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d34d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------\n",
    "# Optional region mapping\n",
    "# ------------------\n",
    "region_map = None\n",
    "if REGION_MAP_PATH.exists():\n",
    "    import json\n",
    "    with REGION_MAP_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        region_map = json.load(f)\n",
    "    region_map.setdefault(\"Unknown\", 0)\n",
    "    print(f\"‚ÑπÔ∏è Loaded region mapping with {len(region_map)} entries.\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No region_mapping.json found. If REGION_CODE is missing in CSVs, default 0 will be used.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e717d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_region_code_from_text(s):\n",
    "    \"\"\"Map text region ‚Üí numeric code. If no map, return 0. Handles NaN.\"\"\"\n",
    "    if region_map is None:\n",
    "        return 0\n",
    "    if pd.isna(s):\n",
    "        return region_map.get(\"Unknown\", 0)\n",
    "    return region_map.get(str(s), region_map.get(\"Unknown\", 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033469b4",
   "metadata": {},
   "source": [
    "# Per country worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55664277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_country(country_path: Path):\n",
    "    country_name = country_path.name\n",
    "    print(f\"\\nüü° Processing: {country_name}\")\n",
    "\n",
    "    try:\n",
    "        # Input paths\n",
    "        csv_path = country_path / f\"{country_name}_segments_vars_with_ratios.csv\"\n",
    "        shp_path = country_path / f\"{country_name}_segments.shp\"\n",
    "\n",
    "        if not csv_path.exists():\n",
    "            print(f\"‚ùå Missing CSV: {csv_path}\")\n",
    "            return\n",
    "        if not shp_path.exists():\n",
    "            print(f\"‚ùå Missing SHP: {shp_path}\")\n",
    "            return\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(csv_path)\n",
    "        n0 = len(df)\n",
    "        print(f\"üìÑ Loaded {csv_path.name} ‚Üí {n0} rows\")\n",
    "\n",
    "        # Ensure REGION_CODE exists if it's part of predictors\n",
    "        if \"REGION_CODE\" in predictor_cols and \"REGION_CODE\" not in df.columns:\n",
    "            if \"REG1_GHSL\" in df.columns:\n",
    "                df[\"REGION_CODE\"] = df[\"REG1_GHSL\"].map(map_region_code_from_text)\n",
    "                print(\"üîß Built REGION_CODE from REG1_GHSL using region map (or default 0).\")\n",
    "            else:\n",
    "                df[\"REGION_CODE\"] = 0\n",
    "                print(\"üîß REGION_CODE not found and REG1_GHSL missing; using 0 for all rows.\")\n",
    "\n",
    "        # Check predictors exist\n",
    "        missing_pred = [c for c in predictor_cols if c not in df.columns]\n",
    "        if missing_pred:\n",
    "            print(f\"‚ùå Missing predictors in CSV: {missing_pred}\")\n",
    "            return\n",
    "\n",
    "        # Drop NA in predictors\n",
    "        df = df.dropna(subset=predictor_cols)\n",
    "        n_after = len(df)\n",
    "        print(f\"üßπ Dropped NA in predictors ‚Üí {n_after} rows (removed {n0 - n_after})\")\n",
    "        if df.empty:\n",
    "            print(f\"‚ö†Ô∏è Skipped {country_name}: all rows dropped after NA-removal in predictors.\")\n",
    "            return\n",
    "\n",
    "        # Predict\n",
    "        X = df[predictor_cols].to_numpy()\n",
    "        if hasattr(rf, \"n_features_in_\"):\n",
    "            if rf.n_features_in_ != X.shape[1]:\n",
    "                print(f\"‚ùå Feature count mismatch: model expects {rf.n_features_in_}, got {X.shape[1]}\")\n",
    "                return\n",
    "\n",
    "        prob = rf.predict_proba(X)[:, 1]\n",
    "        df[\"rf_prob\"] = prob\n",
    "        df[\"rf_label\"] = (df[\"rf_prob\"] >= THRESHOLD).astype(int)\n",
    "\n",
    "        # Build join key (ID_HDC_G0 + ID_SEG, concatenated as strings)\n",
    "        if \"ID_HDC_G0\" not in df.columns or \"ID_SEG\" not in df.columns:\n",
    "            print(f\"‚ùå CSV missing join columns ID_HDC_G0/ID_SEG\")\n",
    "            return\n",
    "        df[\"JOIN_KEY\"] = df[\"ID_HDC_G0\"].astype(str) + df[\"ID_SEG\"].astype(str)\n",
    "\n",
    "        # Load SHP (geometry)\n",
    "        gdf = gpd.read_file(shp_path)\n",
    "        print(f\"üó∫Ô∏è  Loaded {shp_path.name} ‚Üí {len(gdf)} shapes\")\n",
    "\n",
    "        if \"ID_HDC_G0\" not in gdf.columns or \"ID_SEG\" not in gdf.columns:\n",
    "            print(f\"‚ùå SHP missing join columns ID_HDC_G0/ID_SEG\")\n",
    "            return\n",
    "        gdf[\"JOIN_KEY\"] = gdf[\"ID_HDC_G0\"].astype(str) + gdf[\"ID_SEG\"].astype(str)\n",
    "\n",
    "        # Decide which CSV columns to add (avoid overwriting existing GDF cols)\n",
    "        csv_cols_to_add = [c for c in df.columns if c not in gdf.columns and c != \"JOIN_KEY\"]\n",
    "        # Ensure we include predictions even if names collide\n",
    "        for must in [\"rf_prob\", \"rf_label\"]:\n",
    "            if must not in csv_cols_to_add:\n",
    "                csv_cols_to_add.append(must)\n",
    "\n",
    "        # Merge (left join on shapes)\n",
    "        merged = gdf.merge(\n",
    "            df[[\"JOIN_KEY\"] + csv_cols_to_add],\n",
    "            on=\"JOIN_KEY\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "\n",
    "        # Diagnostics\n",
    "        matched = merged[\"rf_prob\"].notna().sum()\n",
    "        print(f\"üîó Match rate: {matched}/{len(merged)} shapes ({matched/len(merged):.1%})\")\n",
    "\n",
    "        # Save to GeoPackage\n",
    "        out_path = OUTPUT_FOLDER / f\"{country_name}_rf_preds.gpkg\"\n",
    "        merged.to_file(out_path, driver=\"GPKG\")\n",
    "        print(f\"‚úÖ Saved: {out_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {country_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e57f9a",
   "metadata": {},
   "source": [
    "# Run over all countries in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e80c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [p for p in PARENT_FOLDER.iterdir() if p.is_dir()]\n",
    "print(f\"\\nFound {len(countries)} country folders under: {PARENT_FOLDER}\")\n",
    "\n",
    "Parallel(n_jobs=N_JOBS, backend=\"loky\")(\n",
    "    delayed(process_country)(country_path) for country_path in countries\n",
    ")\n",
    "\n",
    "print(\"\\nüéâ Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7c7be",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
