{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd64bba",
   "metadata": {},
   "source": [
    "# Filter Cities with â‰¥80% Valid Blocks (QC GPKGs)\n",
    "\n",
    "This notebook:\n",
    "\n",
    "- Reads RF prediction GPKGs: `predictions/{country}_rf_preds.gpkg`\n",
    "- For each **country**:\n",
    "  - Computes, per city, the share of blocks with valid `rf_label` and `POP_SEG`\n",
    "  - Keeps only cities where **PctValid â‰¥ 80%**\n",
    "  - Within those cities, keeps only blocks with valid `rf_label` and `POP_SEG`\n",
    "  - Saves a filtered GPKG with **all original attributes** preserved\n",
    "\n",
    "It also writes a **summary CSV** with basic counts and population before/after filtering.\n",
    "\n",
    "> **Note:** In the analysis behind the manuscript, *all cities passed the 80% QC check*, so the filtered GPKGs are effectively identical to the original prediction files.  \n",
    "> The code is included here for full transparency, so others can reproduce and verify the QC step.\n",
    "  \n",
    "**Inputs**\n",
    "\n",
    "- RF predictions (per-country GPKG):  \n",
    "  `2_modelling/02_application/predictions/{country}_rf_preds.gpkg`  \n",
    "  Required columns: `REG1_GHSL`, `UC_NM_MN`, `rf_label`, `POP_SEG`, `geometry`.\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "- Filtered GPKGs (not stored in GitHub or Zenodo; generated locally if needed):  \n",
    "  `2_modelling/02_application/predictions/Filtered_80pct_allattributes/{country}_rf_preds_filtered80.gpkg`\n",
    "- Summary CSV:  \n",
    "  `2_modelling/02_application/predictions/Filtered_80pct_allattributes/filtered80_new_summary.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eeaeb6",
   "metadata": {},
   "source": [
    "# Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c226ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Paths (relative to 2_modelling/02_application) ---\n",
    "in_folder = Path(\"predictions\")\n",
    "out_folder = in_folder / \"Filtered_80pct_allattributes\"\n",
    "out_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Input predictions folder:\", in_folder.resolve())\n",
    "print(\"Output filtered folder:\", out_folder.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5793e262",
   "metadata": {},
   "source": [
    "# Main loop (filter by 80% valid blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# Filter cities with â‰¥80% valid blocks and SAVE ALL ORIGINAL ATTRS\n",
    "# ===============================================================\n",
    "\n",
    "summary_records = []\n",
    "\n",
    "for gpkg_file in in_folder.glob(\"*_rf_preds.gpkg\"):\n",
    "    country = gpkg_file.stem.replace(\"_rf_preds\", \"\")\n",
    "    print(f\"\\nProcessing {country}...\")\n",
    "\n",
    "    try:\n",
    "        # Load ALL columns to preserve every attribute in the output\n",
    "        gdf = gpd.read_file(gpkg_file)\n",
    "\n",
    "        # Ensure required columns exist\n",
    "        required = {\"REG1_GHSL\", \"UC_NM_MN\", \"rf_label\", \"POP_SEG\", \"geometry\"}\n",
    "        missing = [c for c in required if c not in gdf.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Skipping {country}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # --- Total segments before filtering ---\n",
    "    total_segments = len(gdf)\n",
    "\n",
    "    # --- Coerce rf_label to numeric if needed (e.g., '1'/'0' strings) ---\n",
    "    gdf[\"rf_label\"] = pd.to_numeric(gdf[\"rf_label\"], errors=\"coerce\")\n",
    "\n",
    "    # --- Population before filtering ---\n",
    "    total_pop_before = gdf[\"POP_SEG\"].sum(skipna=True)\n",
    "    deprived_pop_before = gdf.loc[gdf[\"rf_label\"] == 1, \"POP_SEG\"].sum(skipna=True)\n",
    "\n",
    "    # --- Mark valid blocks (both rf_label and POP_SEG present) ---\n",
    "    gdf[\"valid\"] = ~(gdf[\"rf_label\"].isna() | gdf[\"POP_SEG\"].isna())\n",
    "\n",
    "    # --- Compute city-level validity ---\n",
    "    city_stats = (\n",
    "        gdf.groupby(\"UC_NM_MN\")[\"valid\"]\n",
    "        .agg([\"sum\", \"count\"])\n",
    "        .rename(columns={\"sum\": \"ValidBlocks\", \"count\": \"TotalBlocks\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "    city_stats[\"PctValid\"] = (city_stats[\"ValidBlocks\"] / city_stats[\"TotalBlocks\"]) * 100\n",
    "\n",
    "    # --- Determine valid vs discarded cities (â‰¥80% valid blocks) ---\n",
    "    valid_cities = city_stats.loc[city_stats[\"PctValid\"] >= 80, \"UC_NM_MN\"].tolist()\n",
    "    discarded_cities = city_stats.loc[city_stats[\"PctValid\"] < 80, \"UC_NM_MN\"].tolist()\n",
    "\n",
    "    # --- Filter data (keep all attributes, only valid blocks in valid cities) ---\n",
    "    filtered = gdf[gdf[\"UC_NM_MN\"].isin(valid_cities) & gdf[\"valid\"]].copy()\n",
    "\n",
    "    # --- Stats after filtering ---\n",
    "    segments_after = len(filtered)\n",
    "    segments_discarded = total_segments - segments_after\n",
    "\n",
    "    total_pop_after = filtered[\"POP_SEG\"].sum(skipna=True)\n",
    "    deprived_pop_after = filtered.loc[filtered[\"rf_label\"] == 1, \"POP_SEG\"].sum(skipna=True)\n",
    "\n",
    "    # --- Save filtered file (only if it contains data) ---\n",
    "    if not filtered.empty:\n",
    "        out_path = out_folder / f\"{country}_rf_preds_filtered80.gpkg\"\n",
    "\n",
    "        # Drop helper column if you prefer not to keep it in the output\n",
    "        filtered = filtered.drop(columns=[\"valid\"], errors=\"ignore\")\n",
    "\n",
    "        filtered.to_file(out_path, driver=\"GPKG\")\n",
    "        print(\n",
    "            f\"âœ… Saved filtered file for {country} \"\n",
    "            f\"({len(valid_cities)} cities, {segments_after} segments).\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"âš ï¸ No valid data retained for {country}.\")\n",
    "\n",
    "    # --- Append summary record ---\n",
    "    summary_records.append({\n",
    "        \"Country\": country,\n",
    "        \"ValidCities\": len(valid_cities),\n",
    "        \"DiscardedCities\": len(discarded_cities),\n",
    "        \"SegmentsBefore\": total_segments,\n",
    "        \"SegmentsAfter\": segments_after,\n",
    "        \"SegmentsDiscarded\": segments_discarded,\n",
    "        \"TotalPopBefore\": total_pop_before,\n",
    "        \"TotalPopAfter\": total_pop_after,\n",
    "        \"DeprivedPopBefore\": deprived_pop_before,\n",
    "        \"DeprivedPopAfter\": deprived_pop_after\n",
    "    })\n",
    "\n",
    "# --- Write summary CSV ---\n",
    "if summary_records:\n",
    "    summary_df = pd.DataFrame(summary_records)\n",
    "    summary_csv = out_folder / \"filtered80_new_summary.csv\"\n",
    "    summary_df.to_csv(summary_csv, index=False)\n",
    "    print(f\"\\nðŸ“„ Summary written to: {summary_csv}\")\n",
    "else:\n",
    "    print(\"\\nâ„¹ï¸ No files processed successfully; no summary generated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe12c24",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
