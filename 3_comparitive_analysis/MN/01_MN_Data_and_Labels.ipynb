{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd530fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Retrive Million Neighbourhoods (MN) data and create Labels\n",
    "# ================================================================\n",
    "# Purpose:\n",
    "#   1. Read the Million Neighbourhoods (MN) GeoParquet file\n",
    "#   2. Extract per-country MN blocks intersecting DEPRIMAP city segments\n",
    "#   3. For each country, create MN-based deprivation labels for segments\n",
    "#      using Rules A/B/C and majority thresholds 0.1, 0.2, 0.3.\n",
    "#\n",
    "# IMPORTANT DATA NOTES (for GitHub / reproducibility):\n",
    "#   - The original MN GeoParquet is NOT stored in this repo due to size.\n",
    "#     It can be downloaded from:\n",
    "#       https://www.millionneighborhoods.africa/download\n",
    "#     For dataset methodology, see:\n",
    "#       Bettencourt, L.M.A., Marchio, N. (2025),\n",
    "#       \"Infrastructure deficits and informal settlements in sub-Saharan Africa\",\n",
    "#       Nature 645, 399‚Äì406. https://doi.org/10.1038/s41586-025-09465-2\n",
    "#\n",
    "#   - The intermediate per-country MN block files\n",
    "#       MN_Blocks_by_country/{country}_mn_blocks.gpkg\n",
    "#     are NOT shipped in the GitHub repo (size + intermediate nature).\n",
    "#\n",
    "#   - The final MN comparison files\n",
    "#       MN_Comparison_Files/{country}/{country}_segments_mnlabels_k{K_THR}_maj{XX}.gpkg/.csv\n",
    "#     are provided as a single ZIP on Zenodo. In the GitHub repo, a text file\n",
    "#     points to that Zenodo archive instead of storing all GPKGs/CSVs directly.\n",
    "#\n",
    "#   - The label creating part of this notebook MUST be run TWICE:\n",
    "#       1) with K_THR = 3  (high-k = k_complexity > 3)\n",
    "#       2) with K_THR = 5  (high-k = k_complexity > 5)\n",
    "#     Each run writes a separate set of MN label files with the k-threshold\n",
    "#     encoded in the filename, e.g. *_k3_* and *_k5_*.\n",
    "# ================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b6680",
   "metadata": {},
   "source": [
    "# 1Ô∏è‚É£ MN blocks ‚Üí per-country GPKG (retain full blocks; DuckDB reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159c36f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkb\n",
    "\n",
    "# --- EDIT THESE PATHS TO MATCH YOUR LOCAL SETUP ---\n",
    "# MN GeoParquet (NOT included in repo; download from MN website)\n",
    "PARQUET_PATH = Path(\".../MN/africa_geodata.parquet\")\n",
    "\n",
    "# segment files used as ROIs to select MN blocks\n",
    "# (these are your CSD/RF segment predictions; path may differ on your machine)\n",
    "ROIS_DIR = Path(\"../2_modelling/02_application/Filtered_80pct_allattributes/MN_African_Countries\") #the African countries that are part of MN dataset are stored in different folder, but they are same as prediction files in 2_modelling/02_application/predictions\n",
    "\n",
    "\n",
    "# Output folder for per-country MN blocks (INTERMEDIATE; not stored in repo)\n",
    "OUT_DIR_BLOCKS = Path(\"../MN/Outputs/MN_Blocks_by_country\")\n",
    "\n",
    "OUT_DIR_BLOCKS.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10023441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns we want from the MN GeoParquet (subset of full schema)\n",
    "WANT_COLS = [\n",
    "    \"country_name\", \"country_code\",\n",
    "    \"urban_id\", \"urban_center_name\", \"urban_country_name\", \"class_urban_hierarchy\",\n",
    "    \"k_complexity\",\n",
    "    \"building_area_m2\", \"average_building_area_m2\",\n",
    "    \"parcel_count\", \"average_parcel_area_m2\",\n",
    "    \"landscan_population\", \"landscan_population_un\",\n",
    "    \"worldpop_population\", \"worldpop_population_un\",\n",
    "    \"geometry\",\n",
    "]\n",
    "\n",
    "print(\"üîé Discovering available columns via DuckDB‚Ä¶\")\n",
    "schema_df = duckdb.query(\n",
    "    f\"DESCRIBE SELECT * FROM parquet_scan('{PARQUET_PATH.as_posix()}')\"\n",
    ").to_df()\n",
    "available = set(schema_df[\"column_name\"].tolist())\n",
    "\n",
    "# Keep only columns that actually exist in the parquet\n",
    "cols = [c for c in WANT_COLS if c in available]\n",
    "if \"geometry\" not in cols:\n",
    "    raise RuntimeError(\"No 'geometry' column found in the Parquet; cannot proceed.\")\n",
    "\n",
    "missing = [c for c in WANT_COLS if c not in available and c != \"geometry\"]\n",
    "if missing:\n",
    "    print(f\"‚ö†Ô∏è Missing columns (will be skipped): {missing}\")\n",
    "\n",
    "cols_sql = \", \".join(cols)\n",
    "print(\"üì• Reading selected columns from Parquet via DuckDB‚Ä¶\")\n",
    "df = duckdb.query(\n",
    "    f\"SELECT {cols_sql} FROM parquet_scan('{PARQUET_PATH.as_posix()}')\"\n",
    ").to_df()\n",
    "print(f\"‚úÖ Loaded {len(df):,} MN rows\")\n",
    "\n",
    "# ---- Convert geometry (WKB bytes) ‚Üí Shapely ----\n",
    "def _to_geom(v):\n",
    "    if v is None:\n",
    "        return None\n",
    "    try:\n",
    "        return wkb.loads(bytes(v))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "print(\"üîÑ Converting WKB geometries to Shapely‚Ä¶\")\n",
    "geom = df[\"geometry\"].apply(_to_geom)\n",
    "blocks = gpd.GeoDataFrame(df.drop(columns=[\"geometry\"]), geometry=geom)\n",
    "\n",
    "# Set CRS if missing (MN GeoParquet is typically EPSG:4326)\n",
    "if blocks.crs is None:\n",
    "    print(\"‚ÑπÔ∏è Setting MN blocks CRS to EPSG:4326 (adjust if needed).\")\n",
    "    blocks = blocks.set_crs(\"EPSG:4326\")\n",
    "\n",
    "blocks_crs = blocks.crs\n",
    "_ = blocks.sindex  # build spatial index\n",
    "\n",
    "# ---- Helper: parse country name from \"{country}_rf_preds.gpkg\" ----\n",
    "def parse_country_name(path: Path) -> str:\n",
    "    m = re.match(r\"(.+?)_rf_preds\\.gpkg$\", path.name, flags=re.IGNORECASE)\n",
    "    return m.group(1) if m else path.stem\n",
    "\n",
    "roi_files = sorted(ROIS_DIR.glob(\"*_rf_preds.gpkg\"))\n",
    "print(f\"Found {len(roi_files)} ROI files in {ROIS_DIR}\")\n",
    "\n",
    "for roi_path in roi_files:\n",
    "    country = parse_country_name(roi_path)\n",
    "    print(f\"\\n==== {country} ====\")\n",
    "\n",
    "    # Read ROI and reproject to blocks CRS\n",
    "    try:\n",
    "        roi = gpd.read_file(roi_path)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to read ROI {roi_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if roi.empty:\n",
    "        print(\"‚ö†Ô∏è ROI empty; skipping.\")\n",
    "        continue\n",
    "\n",
    "    if roi.crs != blocks_crs:\n",
    "        try:\n",
    "            roi = roi.to_crs(blocks_crs)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to reproject ROI to {blocks_crs}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Disjoint segments are fine; unify for efficient spatial filtering\n",
    "    roi_union = roi.unary_union\n",
    "    if roi_union.is_empty:\n",
    "        print(\"‚ö†Ô∏è ROI union empty; skipping.\")\n",
    "        continue\n",
    "\n",
    "    # BBOX prefilter to reduce candidate set\n",
    "    minx, miny, maxx, maxy = roi_union.bounds\n",
    "    cand_idx = list(blocks.sindex.intersection((minx, miny, maxx, maxy)))\n",
    "    if not cand_idx:\n",
    "        print(\"‚ÑπÔ∏è No MN candidates in ROI bbox; skipping.\")\n",
    "        continue\n",
    "\n",
    "    cand = blocks.iloc[cand_idx].copy()\n",
    "\n",
    "    # Keep full original blocks that intersect the ROI (no geometric clipping)\n",
    "    try:\n",
    "        mask = cand.intersects(roi_union)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå intersects() failed: {e}\")\n",
    "        continue\n",
    "\n",
    "    sel = cand.loc[mask]\n",
    "    if sel.empty:\n",
    "        print(\"‚ÑπÔ∏è No intersecting MN blocks; skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Ensure only requested columns that actually exist (plus geometry)\n",
    "    out_cols = [c for c in WANT_COLS if c in sel.columns or c == \"geometry\"]\n",
    "    sel = sel[out_cols]\n",
    "\n",
    "    out_path = OUT_DIR_BLOCKS / f\"{country}_mn_blocks.gpkg\"\n",
    "    try:\n",
    "        sel.to_file(out_path, layer=\"blocks\", driver=\"GPKG\")\n",
    "        print(f\"‚úÖ Saved {out_path}  ({len(sel):,} blocks)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to write {out_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939700cc",
   "metadata": {},
   "source": [
    "# 2Ô∏è‚É£ MN labels via Rules A/B/C (run TWICE: K_THR = 3 and K_THR = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ca583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely.validation import make_valid\n",
    "from shapely.prepared import prep\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# ---- ROOTS ----\n",
    "# BLK_ROOT: per-country MN blocks created above\n",
    "# OUT_ROOT: where MN label comparison files are written\n",
    "SEG_ROOT = Path(\"../2_modelling/02_application/Filtered_80pct_allattributes/MN_African_Countries\")\n",
    "\n",
    "BLK_ROOT = OUT_DIR_BLOCKS  # use the same folder created above (MN_Country_blocks)\n",
    "OUT_ROOT = Path(\"../MN/Outputs/MN_Comparison_Files\")\n",
    "\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff92c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- THRESHOLDS ----\n",
    "# IMPORTANT: Run this notebook twice: once with K_THR=3 and once with K_THR=5.\n",
    "K_THR = 3          # high-k cutoff (k_complexity > 3 or 5)\n",
    "MAJ_THRS = [0.1, 0.2, 0.3]  # segment-level majority thresholds\n",
    "COVER_THR_A = 0.90          # Rule A: full-cover threshold (>= 90% of segment)\n",
    "EPSILON_M2 = 1.0            # ignore tiny overlaps (< 1 m¬≤)\n",
    "EA_CRS = \"EPSG:6933\"        # equal-area CRS for area calculations\n",
    "\n",
    "# ---- PARALLEL ----\n",
    "N_JOBS = -1      # use all cores; set to e.g. 4 if you prefer\n",
    "VERBOSE = 5      # joblib verbosity\n",
    "GRID_SIZE = 0.05 # meters in EPSG:6933; tweak if needed\n",
    "\n",
    "print(f\"Using K_THR = {K_THR}. Run again with K_THR = 5 for alternative labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d19f8bb",
   "metadata": {},
   "source": [
    "# 3Ô∏è‚É£ Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eb4b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_make_valid(g):\n",
    "    \"\"\"Fix invalid geometries with make_valid, fallback to buffer(0).\"\"\"\n",
    "    if g is None:\n",
    "        return None\n",
    "    try:\n",
    "        gg = make_valid(g)\n",
    "        if gg is None or gg.is_empty:\n",
    "            gg = g.buffer(0)\n",
    "        return gg\n",
    "    except Exception:\n",
    "        try:\n",
    "            return g.buffer(0)\n",
    "        except Exception:\n",
    "            return g\n",
    "\n",
    "def parse_country_from_blocks(path: Path) -> str:\n",
    "    \"\"\"'angola_mn_blocks.gpkg' -> 'angola'.\"\"\"\n",
    "    m = re.match(r\"(.+?)_mn_blocks\\.gpkg$\", path.name, flags=re.IGNORECASE)\n",
    "    return m.group(1) if m else path.stem\n",
    "\n",
    "def seg_label_by_rules(full_cover, full_cover_highk, n_cent, share_cent, share_cov, maj_thr):\n",
    "    \"\"\"\n",
    "    Apply Rules A ‚Üí B ‚Üí C given precomputed metrics for a segment.\n",
    "\n",
    "    Returns:\n",
    "        label (0/1), rule_used ('A', 'B', or 'C')\n",
    "    \"\"\"\n",
    "    # Rule A: single block covers ‚â• COVER_THR_A of the segment\n",
    "    if full_cover >= COVER_THR_A:\n",
    "        return int(full_cover_highk), 'A'\n",
    "\n",
    "    # Rule B: centroid-majority among blocks whose centroids fall inside the segment\n",
    "    if n_cent > 0 and not np.isnan(share_cent):\n",
    "        if share_cent > maj_thr:\n",
    "            return 1, 'B'\n",
    "        if share_cent < maj_thr:\n",
    "            return 0, 'B'\n",
    "        # tie => fall through to Rule C\n",
    "\n",
    "    # Rule C: coverage-share of high-k blocks\n",
    "    share_cov = 0.0 if np.isnan(share_cov) else float(share_cov)\n",
    "    return (1 if share_cov >= maj_thr else 0), 'C'\n",
    "\n",
    "def safe_intersection_area(a, b, grid_size=GRID_SIZE):\n",
    "    \"\"\"\n",
    "    Robust area of intersection in equal-area CRS, with grid snapping and validity fixes.\n",
    "    \"\"\"\n",
    "    if a is None or b is None:\n",
    "        return 0.0\n",
    "    try:\n",
    "        inter = shapely.intersection(a, b, grid_size=grid_size)\n",
    "        if inter is None or inter.is_empty:\n",
    "            return 0.0\n",
    "        return float(inter.area)\n",
    "    except Exception:\n",
    "        # last-resort: try buffer(0) cleanup\n",
    "        try:\n",
    "            aa = make_valid(a)\n",
    "        except Exception:\n",
    "            aa = a.buffer(0)\n",
    "        try:\n",
    "            bb = make_valid(b)\n",
    "        except Exception:\n",
    "            bb = b.buffer(0)\n",
    "        try:\n",
    "            inter2 = shapely.intersection(aa, bb, grid_size=grid_size)\n",
    "            if inter2 is None or inter2.is_empty:\n",
    "                return 0.0\n",
    "            return float(inter2.area)\n",
    "        except Exception:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec0b6d",
   "metadata": {},
   "source": [
    "# 4Ô∏è‚É£ Process one country (build MN labels via Rules A/B/C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_country(country: str):\n",
    "    \"\"\"\n",
    "    Build MN labels for one country with Rules A/B/C.\n",
    "\n",
    "    Inputs:\n",
    "      - {country}_rf_preds_filtered80.gpkg  (segments, in SEG_ROOT)\n",
    "      - {country}_mn_blocks.gpkg           (MN blocks, in BLK_ROOT)\n",
    "\n",
    "    Outputs (written to OUT_ROOT / country):\n",
    "      - {country}_segments_mnlabels_k{K_THR}_maj{XX}.gpkg   (XX = 10, 20, 30)\n",
    "      - {country}_segments_mnlabels_k{K_THR}_maj{XX}.csv\n",
    "    \"\"\"\n",
    "    seg_path = SEG_ROOT / f\"{country}_rf_preds_filtered80.gpkg\"\n",
    "    blk_path = BLK_ROOT / f\"{country}_mn_blocks.gpkg\"\n",
    "\n",
    "    if not blk_path.exists():\n",
    "        return {\"country\": country, \"status\": \"skip_no_blocks\"}\n",
    "\n",
    "    if not seg_path.exists():\n",
    "        return {\"country\": country, \"status\": \"skip_no_segments\"}\n",
    "\n",
    "    # --- output folder per country\n",
    "    out_dir = OUT_ROOT / country\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- load data\n",
    "    try:\n",
    "        segments = gpd.read_file(seg_path)\n",
    "        blocks   = gpd.read_file(blk_path)\n",
    "    except Exception as e:\n",
    "        return {\"country\": country, \"status\": f\"read_error: {e}\"}\n",
    "\n",
    "    if segments.empty:\n",
    "        return {\"country\": country, \"status\": \"empty_segments\"}\n",
    "    if blocks.empty:\n",
    "        return {\"country\": country, \"status\": \"empty_blocks\"}\n",
    "\n",
    "    # --- CRS alignment (work in blocks CRS)\n",
    "    if blocks.crs is None:\n",
    "        blocks = blocks.set_crs(\"EPSG:4326\")\n",
    "    if segments.crs != blocks.crs:\n",
    "        segments = segments.to_crs(blocks.crs)\n",
    "\n",
    "    # --- fix geometries (native CRS)\n",
    "    segments[\"geometry\"] = segments.geometry.apply(safe_make_valid)\n",
    "    blocks[\"geometry\"]   = blocks.geometry.apply(safe_make_valid)\n",
    "\n",
    "    # --- ensure required block fields\n",
    "    if \"k_complexity\" not in blocks.columns:\n",
    "        return {\"country\": country, \"status\": \"missing_k_complexity\"}\n",
    "\n",
    "    # --- derive high-k flag\n",
    "    blocks[\"highk\"] = (blocks[\"k_complexity\"] > K_THR).astype(\"int8\")\n",
    "\n",
    "    # --- equal-area versions for area calcs & precompute segment area\n",
    "    segments_ea = segments.to_crs(EA_CRS)\n",
    "    blocks_ea   = blocks.to_crs(EA_CRS)\n",
    "\n",
    "    segments_ea[\"geometry\"] = segments_ea.geometry.apply(safe_make_valid)\n",
    "    blocks_ea[\"geometry\"]   = blocks_ea.geometry.apply(safe_make_valid)\n",
    "\n",
    "    seg_area = segments_ea.geometry.area.values\n",
    "\n",
    "    # --- spatial index & centroids (native CRS)\n",
    "    sindex = blocks.sindex\n",
    "    blocks_cent = blocks.geometry.centroid\n",
    "\n",
    "    # --- arrays to store metrics per segment\n",
    "    n = len(segments)\n",
    "    full_cover = np.zeros(n, dtype=\"float64\")\n",
    "    full_cover_highk = np.zeros(n, dtype=\"int8\")\n",
    "    n_blocks_intersect = np.zeros(n, dtype=\"int32\")\n",
    "\n",
    "    n_blocks_cent = np.zeros(n, dtype=\"int32\")\n",
    "    share_cent = np.full(n, np.nan, dtype=\"float64\")\n",
    "\n",
    "    share_cov = np.full(n, np.nan, dtype=\"float64\")\n",
    "\n",
    "    # --- iterate segments (sequential within a country)\n",
    "    for i in range(n):\n",
    "        seg = segments.geometry.iat[i]\n",
    "        seg_ea = segments_ea.geometry.iat[i]\n",
    "        area_i = float(seg_area[i])\n",
    "\n",
    "        if seg is None or seg.is_empty or area_i <= 0:\n",
    "            continue\n",
    "\n",
    "        # candidate blocks by bbox; then precise intersects (native CRS)\n",
    "        minx, miny, maxx, maxy = seg.bounds\n",
    "        cand_idx = list(sindex.intersection((minx, miny, maxx, maxy)))\n",
    "        if not cand_idx:\n",
    "            continue\n",
    "\n",
    "        cand     = blocks.iloc[cand_idx]\n",
    "        cand_ea  = blocks_ea.iloc[cand_idx]\n",
    "\n",
    "        inter_mask = cand.geometry.intersects(seg)\n",
    "        if not inter_mask.any():\n",
    "            continue\n",
    "\n",
    "        cand     = cand.loc[inter_mask].copy()\n",
    "        cand_ea  = cand_ea.loc[inter_mask].copy()\n",
    "        n_blocks_intersect[i] = len(cand)\n",
    "\n",
    "        # ---------- Rule A/C metrics: coverage within segment in EA CRS ----------\n",
    "        seg_ea_valid = segments_ea.geometry.iat[i]\n",
    "        prep_seg_ea  = prep(seg_ea_valid)\n",
    "\n",
    "        overlaps = []\n",
    "        for geom in cand_ea.geometry.values:\n",
    "            # quick reject via prepared predicate\n",
    "            if not prep_seg_ea.intersects(geom):\n",
    "                overlaps.append(0.0)\n",
    "                continue\n",
    "            a = safe_intersection_area(geom, seg_ea_valid, grid_size=GRID_SIZE)\n",
    "            overlaps.append(a)\n",
    "\n",
    "        overlaps = np.array(overlaps, dtype=\"float64\")\n",
    "        overlaps[overlaps < EPSILON_M2] = 0.0\n",
    "\n",
    "        cov = overlaps / area_i if area_i > 0 else np.zeros_like(overlaps)\n",
    "\n",
    "        max_cov = float(cov.max()) if cov.size else 0.0\n",
    "        full_cover[i] = max_cov\n",
    "        if max_cov >= COVER_THR_A:\n",
    "            j = int(cov.argmax())\n",
    "            full_cover_highk[i] = int(cand[\"highk\"].iloc[j])\n",
    "\n",
    "        # ---------- Rule B metrics: centroid-majority (native CRS) ----------\n",
    "        cent = blocks_cent.loc[cand.index]\n",
    "        cent_mask = cent.within(seg)\n",
    "        n_cent = int(cent_mask.sum())\n",
    "        n_blocks_cent[i] = n_cent\n",
    "        if n_cent > 0:\n",
    "            assigned = cand.loc[cent_mask]\n",
    "            share_cent[i] = float(assigned[\"highk\"].sum()) / n_cent\n",
    "\n",
    "        # ---------- Rule C metric: coverage-share (of high-k) ----------\n",
    "        if cov.size:\n",
    "            hk_mask = cand[\"highk\"].values.astype(bool)\n",
    "            share_cov[i] = float(cov[hk_mask].sum())\n",
    "\n",
    "    # --- outputs for each majority threshold (reuse metrics) ---\n",
    "    summaries = []\n",
    "    for maj_thr in MAJ_THRS:\n",
    "        labels = np.zeros(n, dtype=\"int8\")\n",
    "        rules  = np.array([\"\"]*n, dtype=object)\n",
    "\n",
    "        for i in range(n):\n",
    "            lab, rule = seg_label_by_rules(\n",
    "                full_cover=full_cover[i],\n",
    "                full_cover_highk=full_cover_highk[i],\n",
    "                n_cent=int(n_blocks_cent[i]),\n",
    "                share_cent=share_cent[i],\n",
    "                share_cov=share_cov[i],\n",
    "                maj_thr=maj_thr\n",
    "            )\n",
    "            labels[i] = lab\n",
    "            rules[i]  = rule\n",
    "\n",
    "        seg_out = segments.copy()\n",
    "        seg_out[\"mn_label\"]            = labels\n",
    "        seg_out[\"mn_rule_used\"]        = rules\n",
    "        seg_out[\"mn_full_cover\"]       = full_cover\n",
    "        seg_out[\"mn_n_blocks_intersect\"]   = n_blocks_intersect\n",
    "        seg_out[\"mn_n_blocks_centroid\"]    = n_blocks_cent\n",
    "        seg_out[\"mn_share_highk_centroid\"] = share_cent\n",
    "        seg_out[\"mn_share_highk_cov\"]      = share_cov\n",
    "        seg_out[\"mn_k_thr\"]                = K_THR\n",
    "        seg_out[\"mn_maj_thr\"]             = maj_thr\n",
    "\n",
    "        # write files\n",
    "        thr_tag = f\"{int(maj_thr*100):02d}\"  # 10, 20, 30\n",
    "        out_gpkg = out_dir / f\"{country}_segments_mnlabels_k{K_THR}_maj{thr_tag}.gpkg\"\n",
    "        out_csv  = out_dir / f\"{country}_segments_mnlabels_k{K_THR}_maj{thr_tag}.csv\"\n",
    "        try:\n",
    "            seg_out.to_file(out_gpkg, layer=\"segments\", driver=\"GPKG\")\n",
    "            seg_out.drop(columns=[\"geometry\"]).to_csv(out_csv, index=False)\n",
    "        except Exception as e:\n",
    "            return {\"country\": country, \"status\": f\"write_error({thr_tag}): {e}\"}\n",
    "\n",
    "        # quick per-threshold summary\n",
    "        s = (\n",
    "            pd.Series(labels)\n",
    "              .value_counts()\n",
    "              .rename_axis(\"label\")\n",
    "              .reset_index(name=\"n\")\n",
    "        )\n",
    "        summaries.append({\"maj_thr\": maj_thr, \"summary\": s})\n",
    "\n",
    "    return {\"country\": country, \"status\": \"ok\", \"n_segments\": n, \"summaries\": summaries}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b375ed6",
   "metadata": {},
   "source": [
    "# 5Ô∏è‚É£ Run all countries in parallel & aggregate counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discover countries from MN_Blocks_by_country folder\n",
    "block_files = sorted(BLK_ROOT.glob(\"*_mn_blocks.gpkg\"))\n",
    "countries = [parse_country_from_blocks(p) for p in block_files]\n",
    "\n",
    "# keep only those that have corresponding segments\n",
    "countries = [\n",
    "    c for c in countries \n",
    "    if (SEG_ROOT / f\"{c}_rf_preds_filtered80.gpkg\").exists()\n",
    "]\n",
    "\n",
    "print(f\"Will process {len(countries)} countries with K_THR={K_THR}:\")\n",
    "print(\", \".join(countries))\n",
    "\n",
    "results = Parallel(n_jobs=N_JOBS, verbose=VERBOSE)(\n",
    "    delayed(process_country)(c) for c in countries\n",
    ")\n",
    "\n",
    "# Collate a simple report\n",
    "report = pd.DataFrame(results)\n",
    "report_path = OUT_ROOT / f\"mn_label_build_report_k{K_THR}.csv\"\n",
    "report.to_csv(report_path, index=False)\n",
    "print(f\"\\n‚úÖ Saved build report to: {report_path}\")\n",
    "\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(report)\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc24ced",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
