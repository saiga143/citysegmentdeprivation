{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa652e2b",
   "metadata": {},
   "source": [
    "# Creating Labeled Training Data for Random Forest (8 IDEABench Cities)\n",
    "\n",
    "This notebook merges:\n",
    "1. **City Segments processed features**  \n",
    "   ‚Üí created in Notebook 01 (`*_segments_vars_with_ratios.csv`)\n",
    "2. **IDEABench-derived slum labels**  \n",
    "   ‚Üí stored in 8 per-city GeoPackages (GPKG)\n",
    "\n",
    "The output is a set of clean CSV files containing:\n",
    "- join keys (`ID_HDC_G0`, `ID_SEG`)\n",
    "- built-environment predictors (i1‚Äìi10, base variables)\n",
    "- `slum_fraction` from IDEABench\n",
    "- `slum_label1` using a threshold of 0.30 (slum_fraction ‚â• 0.30)\n",
    "\n",
    "These labeled CSVs are used in the Random Forest training stage.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è **Data Availability Notes**\n",
    "\n",
    "### **City Segments v1 dataset (raw input)**\n",
    "Not included due to size; download from Harvard Dataverse:\n",
    "\n",
    "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/XLRSF0\n",
    "\n",
    "\n",
    "### **IDEABench slum reference data (GPKG files)**\n",
    "Not included in this repository due to access restrictions.  \n",
    "You must obtain the data from the authors:\n",
    "\n",
    "https://phys-techsciences.datastations.nl/dataset.xhtml?persistentId=doi:10.17026/PT/X4NJII\n",
    "\n",
    "We cannot share the GPKGs in this repository.  \n",
    "Only **the processed labeled CSVs** generated by this notebook will be included in the repo.\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Required Directory Structure\n",
    "\n",
    "Place IDEABench-labelled GPKG files here:\n",
    "\n",
    "../data/private/ideabench_labeled_segments/\n",
    "\n",
    "Buenos_Aires_CSV_with_slum_labels.gpkg\n",
    "\n",
    "Jakarta_CSV_with_slum_labels.gpkg\n",
    "\n",
    "Lagos_CSV_with_slum_labels.gpkg\n",
    "\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7a7e6",
   "metadata": {},
   "source": [
    "\n",
    "## Output labeled CSVs will be saved into:\n",
    "\n",
    "../LabelledData_For_RF/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5133058e",
   "metadata": {},
   "source": [
    "# Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e880e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------\n",
    "# Directory Configuration (relative)\n",
    "# ---------------------------------------\n",
    "\n",
    "# IDEABench-labelled city gpkg directory (not included in repo)\n",
    "GPKG_DIR = Path(\"../data/private/ideabench_labeled_segments\")\n",
    "\n",
    "# Processed City Segments (from Notebook 01)\n",
    "COUNTRY_PARENT = Path(\"../data/raw/CitySegments\")\n",
    "\n",
    "# Output folder (these CSVs WILL be included in the repo)\n",
    "OUT_DIR = Path(\"../LabelledData_For_RF\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Label threshold\n",
    "THRESHOLD = 0.30  # slum_fraction ‚â• 0.30 ‚Üí slum_label1 = 1\n",
    "\n",
    "# Join keys\n",
    "KEY_COLS = [\"ID_HDC_G0\", \"ID_SEG\"]\n",
    "\n",
    "# Mapping from GPKG filename ‚Üí country folder name\n",
    "CITY_TO_COUNTRY = {\n",
    "    \"Buenos_Aires_CSV_with_slum_labels.gpkg\": \"argentina\",\n",
    "    \"Jakarta_CSV_with_slum_labels.gpkg\":      \"indonesia\",\n",
    "    \"Lagos_CSV_with_slum_labels.gpkg\":        \"nigeria\",\n",
    "    \"Medellin_CSV_with_slum_labels.gpkg\":     \"colombia\",\n",
    "    \"Mexico_City_CSV_with_slum_labels.gpkg\":  \"mexico\",\n",
    "    \"Mumbai_CSV_with_slum_labels.gpkg\":       \"india\",\n",
    "    \"Nairobi_CSV_with_slum_labels.gpkg\":      \"kenya\",\n",
    "    \"Salvador_CSV_with_slum_labels.gpkg\":     \"brazil\",\n",
    "}\n",
    "\n",
    "GPKG_DIR, COUNTRY_PARENT, OUT_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97741a9",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c590d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gpkg_labels(gpkg_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads GPKG for one city and extracts join keys and slum attributes.\n",
    "    Geometry is removed to ensure clean CSV output.\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(gpkg_path)\n",
    "\n",
    "    # drop geometry completely\n",
    "    if gdf.geometry is not None:\n",
    "        geom_col = gdf.geometry.name\n",
    "        if geom_col in gdf.columns:\n",
    "            gdf = gdf.drop(columns=geom_col)\n",
    "\n",
    "    df = pd.DataFrame(gdf)\n",
    "\n",
    "    # Ensure join keys exist\n",
    "    for c in KEY_COLS:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"{gpkg_path.name}: missing join key {c}\")\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    keep_cols = [c for c in [\"slum_fraction\", \"slum_label\"] if c in df.columns]\n",
    "    df = df[KEY_COLS + keep_cols].copy()\n",
    "\n",
    "    # Standardize key types\n",
    "    for c in KEY_COLS:\n",
    "        df[c] = df[c].astype(str)\n",
    "\n",
    "    print(f\"‚úîÔ∏è Loaded {gpkg_path.name} ‚Äî columns kept: {df.columns.tolist()}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494168a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_country_subset(country_dir: Path, join_keys: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads the country's *_with_ratios.csv file and keeps only rows\n",
    "    matching the city's join keys.\n",
    "    \"\"\"\n",
    "    country = country_dir.name\n",
    "    csv_path = country_dir / f\"{country}_segments_vars_with_ratios.csv\"\n",
    "\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing CSV: {csv_path}\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    for c in KEY_COLS:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"{csv_path.name}: missing join key {c}\")\n",
    "        df[c] = df[c].astype(str)\n",
    "\n",
    "    # Subset by join keys\n",
    "    return df.merge(join_keys[KEY_COLS], on=KEY_COLS, how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77959ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_label(df_csv: pd.DataFrame, df_gpkg: pd.DataFrame, threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge City Segments features (df_csv) with slum_fraction (df_gpkg)\n",
    "    and create slum_label1 using the provided threshold.\n",
    "    \"\"\"\n",
    "    merged = df_csv.merge(df_gpkg, on=KEY_COLS, how=\"inner\")\n",
    "\n",
    "    # remove any geometry remnants\n",
    "    if \"geometry\" in merged.columns:\n",
    "        merged = merged.drop(columns=\"geometry\")\n",
    "\n",
    "    merged = pd.DataFrame(merged)\n",
    "\n",
    "    # Create thresholded label\n",
    "    if \"slum_fraction\" in merged.columns:\n",
    "        merged[\"slum_fraction\"] = pd.to_numeric(merged[\"slum_fraction\"], errors=\"coerce\")\n",
    "        mask = merged[\"slum_fraction\"].notna()\n",
    "\n",
    "        new_label = pd.Series(pd.NA, index=merged.index, dtype=\"Int64\")\n",
    "        new_label.loc[mask] = (merged.loc[mask, \"slum_fraction\"] >= threshold).astype(\"Int64\")\n",
    "        merged[\"slum_label1\"] = new_label\n",
    "    else:\n",
    "        merged[\"slum_label1\"] = pd.Series(pd.NA, dtype=\"Int64\", index=merged.index)\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccdafa0",
   "metadata": {},
   "source": [
    "# Main workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f643870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    summaries = []\n",
    "\n",
    "    for city_file, country_name in CITY_TO_COUNTRY.items():\n",
    "        try:\n",
    "            city_path = GPKG_DIR / city_file\n",
    "            if not city_path.exists():\n",
    "                print(f\"‚ùå Missing GPKG: {city_file}\")\n",
    "                continue\n",
    "\n",
    "            country_dir = COUNTRY_PARENT / country_name\n",
    "            if not country_dir.exists():\n",
    "                print(f\"‚ùå Missing country folder: {country_dir}\")\n",
    "                continue\n",
    "\n",
    "            # Step 1: load slum labels from GPKG\n",
    "            df_gpkg = read_gpkg_labels(city_path)\n",
    "\n",
    "            # Step 2: load only the matching City Segments rows\n",
    "            df_csv = read_country_subset(country_dir, df_gpkg)\n",
    "\n",
    "            # Step 3: merge + threshold\n",
    "            df_merged = merge_and_label(df_csv, df_gpkg, THRESHOLD)\n",
    "\n",
    "            # Step 4: remove geometry-like columns if they sneak in\n",
    "            geom_like = [c for c in df_merged.columns if \"geom\" in c.lower()]\n",
    "            if geom_like:\n",
    "                print(f\"‚ö†Ô∏è {city_file} ‚Äî geometry-like columns removed: {geom_like}\")\n",
    "                df_merged = df_merged.drop(columns=geom_like)\n",
    "\n",
    "            # Step 5: save CSV output (included in GitHub repo)\n",
    "            city_stem = city_path.stem.replace(\"_CSV_with_slum_labels\", \"\")\n",
    "            out_name = f\"{city_stem.lower()}_labeled_thr030.csv\"\n",
    "            out_path = OUT_DIR / out_name\n",
    "            df_merged.to_csv(out_path, index=False)\n",
    "\n",
    "            # Step 6: summarize\n",
    "            n = len(df_merged)\n",
    "            n_nan_frac = df_merged[\"slum_fraction\"].isna().sum() if \"slum_fraction\" in df_merged else n\n",
    "            n_ones = int((df_merged[\"slum_label1\"] == 1).sum())\n",
    "            n_zeros = int((df_merged[\"slum_label1\"] == 0).sum())\n",
    "            n_na = df_merged[\"slum_label1\"].isna().sum()\n",
    "\n",
    "            summaries.append(\n",
    "                f\"‚úîÔ∏è {city_stem:<12} | {country_name:<10} | rows: {n:>7,d} | \"\n",
    "                f\"slum_fraction NaN: {n_nan_frac:>6,d} | \"\n",
    "                f\"label1 ‚Üí 1:{n_ones:>6,d}, 0:{n_zeros:>6,d}, NA:{n_na:>6,d} | \"\n",
    "                f\"saved ‚Üí {out_name}\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            summaries.append(f\"‚ùå {city_file:<35} | {country_name:<10} | ERROR: {e}\")\n",
    "\n",
    "    print(\"\\n\".join(summaries))\n",
    "    print(\"\\nüéâ Done ‚Äî all labeled CSVs created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af79552",
   "metadata": {},
   "source": [
    "# Run the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93a916",
   "metadata": {},
   "source": [
    "## Outputs generated\n",
    "\n",
    "../LabelledData_For_RF/\n",
    "\n",
    "    buenos_aires_labeled_thr030.csv \n",
    "\n",
    "    jakarta_labeled_thr030.csv\n",
    "\n",
    "    lagos_labeled_thr030.csv\n",
    "\n",
    "    ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c2c512",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
